{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 16:50:27.468472: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-14 16:50:27.516610: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model (n_hidden=3, n_units=100, learning_rate=0.01):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "    for i in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_units, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=learning_rate),\n",
    "              metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 16:50:29.281418: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "Epoch 1/45\n",
      "860/860 [==============================] - 1s 693us/step - loss: 1.3602 - accuracy: 0.5557 - val_loss: 0.9353 - val_accuracy: 0.6628\n",
      "Epoch 2/45\n",
      "860/860 [==============================] - 0s 568us/step - loss: 0.8583 - accuracy: 0.6808 - val_loss: 0.7960 - val_accuracy: 0.7036\n",
      "Epoch 3/45\n",
      "860/860 [==============================] - 0s 570us/step - loss: 0.7667 - accuracy: 0.7217 - val_loss: 0.7203 - val_accuracy: 0.7446\n",
      "Epoch 4/45\n",
      "860/860 [==============================] - 0s 566us/step - loss: 0.7114 - accuracy: 0.7475 - val_loss: 0.6870 - val_accuracy: 0.7632\n",
      "Epoch 5/45\n",
      "860/860 [==============================] - 0s 571us/step - loss: 0.6727 - accuracy: 0.7651 - val_loss: 0.6719 - val_accuracy: 0.7570\n",
      "Epoch 6/45\n",
      "860/860 [==============================] - 0s 570us/step - loss: 0.6441 - accuracy: 0.7760 - val_loss: 0.6183 - val_accuracy: 0.7938\n",
      "Epoch 7/45\n",
      "860/860 [==============================] - 1s 598us/step - loss: 0.6245 - accuracy: 0.7830 - val_loss: 0.6045 - val_accuracy: 0.7984\n",
      "Epoch 8/45\n",
      "860/860 [==============================] - 0s 567us/step - loss: 0.6074 - accuracy: 0.7876 - val_loss: 0.5876 - val_accuracy: 0.8044\n",
      "Epoch 9/45\n",
      "860/860 [==============================] - 0s 567us/step - loss: 0.5958 - accuracy: 0.7932 - val_loss: 0.6006 - val_accuracy: 0.7994\n",
      "Epoch 10/45\n",
      "860/860 [==============================] - 0s 571us/step - loss: 0.5863 - accuracy: 0.7949 - val_loss: 0.5729 - val_accuracy: 0.8088\n",
      "Epoch 11/45\n",
      "860/860 [==============================] - 0s 575us/step - loss: 0.5771 - accuracy: 0.7990 - val_loss: 0.5657 - val_accuracy: 0.8084\n",
      "Epoch 12/45\n",
      "860/860 [==============================] - 0s 565us/step - loss: 0.5703 - accuracy: 0.8001 - val_loss: 0.5567 - val_accuracy: 0.8150\n",
      "Epoch 13/45\n",
      "860/860 [==============================] - 0s 563us/step - loss: 0.5647 - accuracy: 0.8023 - val_loss: 0.5887 - val_accuracy: 0.8016\n",
      "Epoch 14/45\n",
      "860/860 [==============================] - 0s 570us/step - loss: 0.5594 - accuracy: 0.8054 - val_loss: 0.5499 - val_accuracy: 0.8136\n",
      "Epoch 15/45\n",
      "860/860 [==============================] - 0s 573us/step - loss: 0.5539 - accuracy: 0.8062 - val_loss: 0.5474 - val_accuracy: 0.8162\n",
      "Epoch 16/45\n",
      "860/860 [==============================] - 0s 572us/step - loss: 0.5496 - accuracy: 0.8081 - val_loss: 0.6010 - val_accuracy: 0.7834\n",
      "Epoch 17/45\n",
      "860/860 [==============================] - 0s 568us/step - loss: 0.5459 - accuracy: 0.8083 - val_loss: 0.5519 - val_accuracy: 0.8164\n",
      "Epoch 18/45\n",
      "860/860 [==============================] - 0s 576us/step - loss: 0.5428 - accuracy: 0.8115 - val_loss: 0.5452 - val_accuracy: 0.8186\n",
      "Epoch 19/45\n",
      "860/860 [==============================] - 0s 569us/step - loss: 0.5396 - accuracy: 0.8123 - val_loss: 0.5536 - val_accuracy: 0.8146\n",
      "Epoch 20/45\n",
      "860/860 [==============================] - 0s 566us/step - loss: 0.5359 - accuracy: 0.8127 - val_loss: 0.5395 - val_accuracy: 0.8200\n",
      "Epoch 21/45\n",
      "860/860 [==============================] - 0s 572us/step - loss: 0.5326 - accuracy: 0.8144 - val_loss: 0.5421 - val_accuracy: 0.8230\n",
      "Epoch 22/45\n",
      "860/860 [==============================] - 0s 575us/step - loss: 0.5301 - accuracy: 0.8135 - val_loss: 0.5509 - val_accuracy: 0.8146\n",
      "Epoch 23/45\n",
      "860/860 [==============================] - 0s 573us/step - loss: 0.5273 - accuracy: 0.8157 - val_loss: 0.5373 - val_accuracy: 0.8212\n",
      "Epoch 24/45\n",
      "860/860 [==============================] - 0s 577us/step - loss: 0.5244 - accuracy: 0.8172 - val_loss: 0.5300 - val_accuracy: 0.8230\n",
      "Epoch 25/45\n",
      "860/860 [==============================] - 0s 579us/step - loss: 0.5230 - accuracy: 0.8171 - val_loss: 0.5305 - val_accuracy: 0.8194\n",
      "Epoch 26/45\n",
      "860/860 [==============================] - 1s 599us/step - loss: 0.5210 - accuracy: 0.8183 - val_loss: 0.5365 - val_accuracy: 0.8214\n",
      "Epoch 27/45\n",
      "860/860 [==============================] - 1s 614us/step - loss: 0.5195 - accuracy: 0.8201 - val_loss: 0.5278 - val_accuracy: 0.8246\n",
      "Epoch 28/45\n",
      "860/860 [==============================] - 1s 596us/step - loss: 0.5165 - accuracy: 0.8188 - val_loss: 0.5366 - val_accuracy: 0.8206\n",
      "Epoch 29/45\n",
      "860/860 [==============================] - 1s 606us/step - loss: 0.5153 - accuracy: 0.8199 - val_loss: 0.5329 - val_accuracy: 0.8232\n",
      "Epoch 30/45\n",
      "860/860 [==============================] - 1s 581us/step - loss: 0.5125 - accuracy: 0.8222 - val_loss: 0.5454 - val_accuracy: 0.8224\n",
      "Epoch 31/45\n",
      "860/860 [==============================] - 1s 581us/step - loss: 0.5114 - accuracy: 0.8221 - val_loss: 0.5200 - val_accuracy: 0.8258\n",
      "Epoch 32/45\n",
      "860/860 [==============================] - 0s 568us/step - loss: 0.5088 - accuracy: 0.8224 - val_loss: 0.5635 - val_accuracy: 0.8032\n",
      "Epoch 33/45\n",
      "860/860 [==============================] - 1s 582us/step - loss: 0.5073 - accuracy: 0.8251 - val_loss: 0.5235 - val_accuracy: 0.8260\n",
      "Epoch 34/45\n",
      "860/860 [==============================] - 0s 559us/step - loss: 0.5069 - accuracy: 0.8233 - val_loss: 0.5437 - val_accuracy: 0.8186\n",
      "Epoch 35/45\n",
      "860/860 [==============================] - 0s 570us/step - loss: 0.5050 - accuracy: 0.8259 - val_loss: 0.5222 - val_accuracy: 0.8260\n",
      "Epoch 36/45\n",
      "860/860 [==============================] - 0s 553us/step - loss: 0.5039 - accuracy: 0.8249 - val_loss: 0.5206 - val_accuracy: 0.8248\n",
      "Epoch 37/45\n",
      "860/860 [==============================] - 0s 558us/step - loss: 0.5021 - accuracy: 0.8249 - val_loss: 0.5295 - val_accuracy: 0.8236\n",
      "Epoch 38/45\n",
      "860/860 [==============================] - 0s 558us/step - loss: 0.5008 - accuracy: 0.8268 - val_loss: 0.5367 - val_accuracy: 0.8194\n",
      "Epoch 39/45\n",
      "860/860 [==============================] - 0s 560us/step - loss: 0.5000 - accuracy: 0.8267 - val_loss: 0.5167 - val_accuracy: 0.8256\n",
      "Epoch 40/45\n",
      "860/860 [==============================] - 0s 571us/step - loss: 0.4987 - accuracy: 0.8268 - val_loss: 0.5149 - val_accuracy: 0.8264\n",
      "Epoch 41/45\n",
      "860/860 [==============================] - 0s 574us/step - loss: 0.4969 - accuracy: 0.8280 - val_loss: 0.5153 - val_accuracy: 0.8272\n",
      "Epoch 42/45\n",
      "860/860 [==============================] - 0s 552us/step - loss: 0.4944 - accuracy: 0.8289 - val_loss: 0.5173 - val_accuracy: 0.8264\n",
      "Epoch 43/45\n",
      "860/860 [==============================] - 0s 561us/step - loss: 0.4955 - accuracy: 0.8296 - val_loss: 0.5121 - val_accuracy: 0.8262\n",
      "Epoch 44/45\n",
      "860/860 [==============================] - 0s 568us/step - loss: 0.4926 - accuracy: 0.8310 - val_loss: 0.5213 - val_accuracy: 0.8212\n",
      "Epoch 45/45\n",
      "860/860 [==============================] - 0s 562us/step - loss: 0.4936 - accuracy: 0.8279 - val_loss: 0.5202 - val_accuracy: 0.8286\n",
      "860/860 [==============================] - 0s 330us/step\n",
      "[CV] END learning_rate=0.022174573948353465, n_hidden=1, n_units=4; total time=  23.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "860/860 [==============================] - 1s 651us/step - loss: 1.6250 - accuracy: 0.4299 - val_loss: 1.2274 - val_accuracy: 0.5418\n",
      "Epoch 2/45\n",
      "860/860 [==============================] - 0s 580us/step - loss: 1.1193 - accuracy: 0.5823 - val_loss: 1.0009 - val_accuracy: 0.6296\n",
      "Epoch 3/45\n",
      "860/860 [==============================] - 0s 559us/step - loss: 0.9557 - accuracy: 0.6463 - val_loss: 0.8850 - val_accuracy: 0.6810\n",
      "Epoch 4/45\n",
      "860/860 [==============================] - 0s 567us/step - loss: 0.8517 - accuracy: 0.6865 - val_loss: 0.7956 - val_accuracy: 0.7120\n",
      "Epoch 5/45\n",
      "860/860 [==============================] - 0s 577us/step - loss: 0.7750 - accuracy: 0.7136 - val_loss: 0.7359 - val_accuracy: 0.7290\n",
      "Epoch 6/45\n",
      "860/860 [==============================] - 0s 554us/step - loss: 0.7244 - accuracy: 0.7374 - val_loss: 0.6999 - val_accuracy: 0.7460\n",
      "Epoch 7/45\n",
      "860/860 [==============================] - 0s 574us/step - loss: 0.6902 - accuracy: 0.7561 - val_loss: 0.6739 - val_accuracy: 0.7658\n",
      "Epoch 8/45\n",
      "860/860 [==============================] - 1s 587us/step - loss: 0.6627 - accuracy: 0.7684 - val_loss: 0.6468 - val_accuracy: 0.7788\n",
      "Epoch 9/45\n",
      "860/860 [==============================] - 1s 582us/step - loss: 0.6390 - accuracy: 0.7788 - val_loss: 0.6248 - val_accuracy: 0.7892\n",
      "Epoch 10/45\n",
      "860/860 [==============================] - 1s 587us/step - loss: 0.6213 - accuracy: 0.7865 - val_loss: 0.6241 - val_accuracy: 0.7852\n",
      "Epoch 11/45\n",
      "860/860 [==============================] - 0s 572us/step - loss: 0.6067 - accuracy: 0.7917 - val_loss: 0.6025 - val_accuracy: 0.7966\n",
      "Epoch 12/45\n",
      "860/860 [==============================] - 0s 566us/step - loss: 0.5938 - accuracy: 0.7956 - val_loss: 0.5883 - val_accuracy: 0.7994\n",
      "Epoch 13/45\n",
      "860/860 [==============================] - 0s 562us/step - loss: 0.5842 - accuracy: 0.7987 - val_loss: 0.6110 - val_accuracy: 0.7954\n",
      "Epoch 14/45\n",
      "860/860 [==============================] - 0s 556us/step - loss: 0.5767 - accuracy: 0.8023 - val_loss: 0.5686 - val_accuracy: 0.8052\n",
      "Epoch 15/45\n",
      "860/860 [==============================] - 0s 553us/step - loss: 0.5686 - accuracy: 0.8043 - val_loss: 0.5671 - val_accuracy: 0.8088\n",
      "Epoch 16/45\n",
      "860/860 [==============================] - 0s 557us/step - loss: 0.5609 - accuracy: 0.8053 - val_loss: 0.5589 - val_accuracy: 0.8118\n",
      "Epoch 17/45\n",
      "860/860 [==============================] - 0s 566us/step - loss: 0.5561 - accuracy: 0.8078 - val_loss: 0.5662 - val_accuracy: 0.8076\n",
      "Epoch 18/45\n",
      "860/860 [==============================] - 0s 577us/step - loss: 0.5499 - accuracy: 0.8105 - val_loss: 0.5584 - val_accuracy: 0.8122\n",
      "Epoch 19/45\n",
      "860/860 [==============================] - 1s 604us/step - loss: 0.5454 - accuracy: 0.8127 - val_loss: 0.5654 - val_accuracy: 0.8088\n",
      "Epoch 20/45\n",
      "860/860 [==============================] - 1s 586us/step - loss: 0.5408 - accuracy: 0.8152 - val_loss: 0.5499 - val_accuracy: 0.8124\n",
      "Epoch 21/45\n",
      "860/860 [==============================] - 0s 571us/step - loss: 0.5374 - accuracy: 0.8171 - val_loss: 0.5409 - val_accuracy: 0.8188\n",
      "Epoch 22/45\n",
      "860/860 [==============================] - 0s 570us/step - loss: 0.5336 - accuracy: 0.8165 - val_loss: 0.5572 - val_accuracy: 0.8084\n",
      "Epoch 23/45\n",
      "860/860 [==============================] - 1s 592us/step - loss: 0.5301 - accuracy: 0.8187 - val_loss: 0.5405 - val_accuracy: 0.8224\n",
      "Epoch 24/45\n",
      "860/860 [==============================] - 0s 567us/step - loss: 0.5273 - accuracy: 0.8201 - val_loss: 0.5370 - val_accuracy: 0.8190\n",
      "Epoch 25/45\n",
      "860/860 [==============================] - 0s 556us/step - loss: 0.5242 - accuracy: 0.8210 - val_loss: 0.5414 - val_accuracy: 0.8190\n",
      "Epoch 26/45\n",
      "860/860 [==============================] - 0s 554us/step - loss: 0.5217 - accuracy: 0.8208 - val_loss: 0.5391 - val_accuracy: 0.8226\n",
      "Epoch 27/45\n",
      "860/860 [==============================] - 0s 552us/step - loss: 0.5198 - accuracy: 0.8231 - val_loss: 0.5338 - val_accuracy: 0.8196\n",
      "Epoch 28/45\n",
      "860/860 [==============================] - 0s 562us/step - loss: 0.5157 - accuracy: 0.8220 - val_loss: 0.5442 - val_accuracy: 0.8152\n",
      "Epoch 29/45\n",
      "860/860 [==============================] - 0s 560us/step - loss: 0.5148 - accuracy: 0.8241 - val_loss: 0.5641 - val_accuracy: 0.8040\n",
      "Epoch 30/45\n",
      "860/860 [==============================] - 0s 555us/step - loss: 0.5122 - accuracy: 0.8245 - val_loss: 0.5277 - val_accuracy: 0.8226\n",
      "Epoch 31/45\n",
      "860/860 [==============================] - 0s 563us/step - loss: 0.5103 - accuracy: 0.8260 - val_loss: 0.5313 - val_accuracy: 0.8200\n",
      "Epoch 32/45\n",
      "860/860 [==============================] - 0s 557us/step - loss: 0.5079 - accuracy: 0.8269 - val_loss: 0.5263 - val_accuracy: 0.8200\n",
      "Epoch 33/45\n",
      "860/860 [==============================] - 0s 556us/step - loss: 0.5069 - accuracy: 0.8260 - val_loss: 0.5209 - val_accuracy: 0.8238\n",
      "Epoch 34/45\n",
      "860/860 [==============================] - 0s 560us/step - loss: 0.5047 - accuracy: 0.8269 - val_loss: 0.5216 - val_accuracy: 0.8242\n",
      "Epoch 35/45\n",
      "860/860 [==============================] - 0s 561us/step - loss: 0.5026 - accuracy: 0.8277 - val_loss: 0.5201 - val_accuracy: 0.8252\n",
      "Epoch 36/45\n",
      "860/860 [==============================] - 0s 560us/step - loss: 0.5008 - accuracy: 0.8280 - val_loss: 0.5730 - val_accuracy: 0.8016\n",
      "Epoch 37/45\n",
      "860/860 [==============================] - 0s 569us/step - loss: 0.5007 - accuracy: 0.8281 - val_loss: 0.5281 - val_accuracy: 0.8208\n",
      "Epoch 38/45\n",
      "860/860 [==============================] - 0s 558us/step - loss: 0.4980 - accuracy: 0.8276 - val_loss: 0.5149 - val_accuracy: 0.8244\n",
      "Epoch 39/45\n",
      "860/860 [==============================] - 0s 562us/step - loss: 0.4976 - accuracy: 0.8287 - val_loss: 0.5173 - val_accuracy: 0.8262\n",
      "Epoch 40/45\n",
      "860/860 [==============================] - 0s 557us/step - loss: 0.4949 - accuracy: 0.8307 - val_loss: 0.5125 - val_accuracy: 0.8282\n",
      "Epoch 41/45\n",
      "860/860 [==============================] - 0s 561us/step - loss: 0.4941 - accuracy: 0.8304 - val_loss: 0.5121 - val_accuracy: 0.8296\n",
      "Epoch 42/45\n",
      "860/860 [==============================] - 0s 559us/step - loss: 0.4921 - accuracy: 0.8312 - val_loss: 0.5470 - val_accuracy: 0.8102\n",
      "Epoch 43/45\n",
      "860/860 [==============================] - 0s 559us/step - loss: 0.4921 - accuracy: 0.8305 - val_loss: 0.5329 - val_accuracy: 0.8212\n",
      "Epoch 44/45\n",
      "860/860 [==============================] - 0s 565us/step - loss: 0.4907 - accuracy: 0.8315 - val_loss: 0.5168 - val_accuracy: 0.8250\n",
      "Epoch 45/45\n",
      "860/860 [==============================] - 0s 559us/step - loss: 0.4892 - accuracy: 0.8317 - val_loss: 0.5218 - val_accuracy: 0.8236\n",
      "860/860 [==============================] - 0s 337us/step\n",
      "[CV] END learning_rate=0.022174573948353465, n_hidden=1, n_units=4; total time=  22.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "860/860 [==============================] - 1s 779us/step - loss: 0.9341 - accuracy: 0.6982 - val_loss: 0.6242 - val_accuracy: 0.7990\n",
      "Epoch 2/45\n",
      "860/860 [==============================] - 1s 705us/step - loss: 0.5870 - accuracy: 0.7995 - val_loss: 0.5364 - val_accuracy: 0.8170\n",
      "Epoch 3/45\n",
      "860/860 [==============================] - 1s 713us/step - loss: 0.5241 - accuracy: 0.8189 - val_loss: 0.4981 - val_accuracy: 0.8282\n",
      "Epoch 4/45\n",
      "860/860 [==============================] - 1s 710us/step - loss: 0.4892 - accuracy: 0.8277 - val_loss: 0.4728 - val_accuracy: 0.8388\n",
      "Epoch 5/45\n",
      "860/860 [==============================] - 1s 740us/step - loss: 0.4665 - accuracy: 0.8356 - val_loss: 0.5174 - val_accuracy: 0.8158\n",
      "Epoch 6/45\n",
      "860/860 [==============================] - 1s 717us/step - loss: 0.4463 - accuracy: 0.8417 - val_loss: 0.4414 - val_accuracy: 0.8478\n",
      "Epoch 7/45\n",
      "860/860 [==============================] - 1s 721us/step - loss: 0.4325 - accuracy: 0.8484 - val_loss: 0.4647 - val_accuracy: 0.8402\n",
      "Epoch 8/45\n",
      "860/860 [==============================] - 1s 723us/step - loss: 0.4178 - accuracy: 0.8547 - val_loss: 0.4161 - val_accuracy: 0.8622\n",
      "Epoch 9/45\n",
      "860/860 [==============================] - 1s 738us/step - loss: 0.4089 - accuracy: 0.8563 - val_loss: 0.4515 - val_accuracy: 0.8460\n",
      "Epoch 10/45\n",
      "860/860 [==============================] - 1s 714us/step - loss: 0.4002 - accuracy: 0.8609 - val_loss: 0.4168 - val_accuracy: 0.8540\n",
      "Epoch 11/45\n",
      "860/860 [==============================] - 1s 726us/step - loss: 0.3899 - accuracy: 0.8628 - val_loss: 0.4052 - val_accuracy: 0.8626\n",
      "Epoch 12/45\n",
      "860/860 [==============================] - 1s 712us/step - loss: 0.3815 - accuracy: 0.8654 - val_loss: 0.3833 - val_accuracy: 0.8656\n",
      "Epoch 13/45\n",
      "860/860 [==============================] - 1s 696us/step - loss: 0.3760 - accuracy: 0.8685 - val_loss: 0.4314 - val_accuracy: 0.8506\n",
      "Epoch 14/45\n",
      "860/860 [==============================] - 1s 703us/step - loss: 0.3697 - accuracy: 0.8704 - val_loss: 0.3864 - val_accuracy: 0.8664\n",
      "Epoch 15/45\n",
      "860/860 [==============================] - 1s 719us/step - loss: 0.3632 - accuracy: 0.8729 - val_loss: 0.3776 - val_accuracy: 0.8694\n",
      "Epoch 16/45\n",
      "860/860 [==============================] - 1s 740us/step - loss: 0.3571 - accuracy: 0.8755 - val_loss: 0.4287 - val_accuracy: 0.8478\n",
      "Epoch 17/45\n",
      "860/860 [==============================] - 1s 720us/step - loss: 0.3508 - accuracy: 0.8767 - val_loss: 0.3780 - val_accuracy: 0.8694\n",
      "Epoch 18/45\n",
      "860/860 [==============================] - 1s 722us/step - loss: 0.3462 - accuracy: 0.8793 - val_loss: 0.3841 - val_accuracy: 0.8670\n",
      "Epoch 19/45\n",
      "860/860 [==============================] - 1s 722us/step - loss: 0.3408 - accuracy: 0.8797 - val_loss: 0.3887 - val_accuracy: 0.8600\n",
      "Epoch 20/45\n",
      "860/860 [==============================] - 1s 731us/step - loss: 0.3359 - accuracy: 0.8809 - val_loss: 0.3574 - val_accuracy: 0.8770\n",
      "Epoch 21/45\n",
      "860/860 [==============================] - 1s 705us/step - loss: 0.3328 - accuracy: 0.8826 - val_loss: 0.3626 - val_accuracy: 0.8720\n",
      "Epoch 22/45\n",
      "860/860 [==============================] - 1s 726us/step - loss: 0.3282 - accuracy: 0.8845 - val_loss: 0.3738 - val_accuracy: 0.8722\n",
      "Epoch 23/45\n",
      "860/860 [==============================] - 1s 722us/step - loss: 0.3224 - accuracy: 0.8867 - val_loss: 0.3622 - val_accuracy: 0.8732\n",
      "Epoch 24/45\n",
      "860/860 [==============================] - 1s 728us/step - loss: 0.3184 - accuracy: 0.8869 - val_loss: 0.3634 - val_accuracy: 0.8738\n",
      "Epoch 25/45\n",
      "860/860 [==============================] - 1s 729us/step - loss: 0.3137 - accuracy: 0.8889 - val_loss: 0.3626 - val_accuracy: 0.8766\n",
      "Epoch 26/45\n",
      "860/860 [==============================] - 1s 737us/step - loss: 0.3101 - accuracy: 0.8915 - val_loss: 0.3586 - val_accuracy: 0.8746\n",
      "Epoch 27/45\n",
      "860/860 [==============================] - 1s 722us/step - loss: 0.3063 - accuracy: 0.8920 - val_loss: 0.3570 - val_accuracy: 0.8770\n",
      "Epoch 28/45\n",
      "860/860 [==============================] - 1s 695us/step - loss: 0.3026 - accuracy: 0.8927 - val_loss: 0.3812 - val_accuracy: 0.8642\n",
      "Epoch 29/45\n",
      "860/860 [==============================] - 1s 715us/step - loss: 0.2992 - accuracy: 0.8947 - val_loss: 0.3520 - val_accuracy: 0.8770\n",
      "Epoch 30/45\n",
      "860/860 [==============================] - 1s 703us/step - loss: 0.2940 - accuracy: 0.8955 - val_loss: 0.3581 - val_accuracy: 0.8742\n",
      "Epoch 31/45\n",
      "860/860 [==============================] - 1s 696us/step - loss: 0.2910 - accuracy: 0.8976 - val_loss: 0.3533 - val_accuracy: 0.8762\n",
      "Epoch 32/45\n",
      "860/860 [==============================] - 1s 722us/step - loss: 0.2872 - accuracy: 0.8977 - val_loss: 0.3655 - val_accuracy: 0.8736\n",
      "Epoch 33/45\n",
      "860/860 [==============================] - 1s 701us/step - loss: 0.2839 - accuracy: 0.8992 - val_loss: 0.3428 - val_accuracy: 0.8786\n",
      "Epoch 34/45\n",
      "860/860 [==============================] - 1s 699us/step - loss: 0.2822 - accuracy: 0.8995 - val_loss: 0.3621 - val_accuracy: 0.8752\n",
      "Epoch 35/45\n",
      "860/860 [==============================] - 1s 694us/step - loss: 0.2777 - accuracy: 0.9013 - val_loss: 0.3485 - val_accuracy: 0.8786\n",
      "Epoch 36/45\n",
      "860/860 [==============================] - 1s 704us/step - loss: 0.2746 - accuracy: 0.9028 - val_loss: 0.3757 - val_accuracy: 0.8660\n",
      "Epoch 37/45\n",
      "860/860 [==============================] - 1s 720us/step - loss: 0.2718 - accuracy: 0.9035 - val_loss: 0.3628 - val_accuracy: 0.8692\n",
      "Epoch 38/45\n",
      "860/860 [==============================] - 1s 691us/step - loss: 0.2689 - accuracy: 0.9051 - val_loss: 0.3564 - val_accuracy: 0.8728\n",
      "Epoch 39/45\n",
      "860/860 [==============================] - 1s 709us/step - loss: 0.2651 - accuracy: 0.9061 - val_loss: 0.3386 - val_accuracy: 0.8848\n",
      "Epoch 40/45\n",
      "860/860 [==============================] - 1s 703us/step - loss: 0.2619 - accuracy: 0.9071 - val_loss: 0.3384 - val_accuracy: 0.8802\n",
      "Epoch 41/45\n",
      "860/860 [==============================] - 1s 713us/step - loss: 0.2593 - accuracy: 0.9086 - val_loss: 0.3426 - val_accuracy: 0.8786\n",
      "Epoch 42/45\n",
      "860/860 [==============================] - 1s 705us/step - loss: 0.2554 - accuracy: 0.9095 - val_loss: 0.3404 - val_accuracy: 0.8804\n",
      "Epoch 43/45\n",
      "860/860 [==============================] - 1s 714us/step - loss: 0.2530 - accuracy: 0.9101 - val_loss: 0.3391 - val_accuracy: 0.8812\n",
      "Epoch 44/45\n",
      "860/860 [==============================] - 1s 713us/step - loss: 0.2501 - accuracy: 0.9126 - val_loss: 0.3563 - val_accuracy: 0.8734\n",
      "Epoch 45/45\n",
      "860/860 [==============================] - 1s 769us/step - loss: 0.2499 - accuracy: 0.9101 - val_loss: 0.3520 - val_accuracy: 0.8758\n",
      "860/860 [==============================] - 0s 382us/step\n",
      "[CV] END learning_rate=0.005432590230265345, n_hidden=2, n_units=94; total time=  28.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "860/860 [==============================] - 1s 787us/step - loss: 0.9211 - accuracy: 0.7014 - val_loss: 0.6180 - val_accuracy: 0.7930\n",
      "Epoch 2/45\n",
      "860/860 [==============================] - 1s 714us/step - loss: 0.5799 - accuracy: 0.7999 - val_loss: 0.6133 - val_accuracy: 0.7804\n",
      "Epoch 3/45\n",
      "860/860 [==============================] - 1s 705us/step - loss: 0.5172 - accuracy: 0.8197 - val_loss: 0.5183 - val_accuracy: 0.8272\n",
      "Epoch 4/45\n",
      "860/860 [==============================] - 1s 718us/step - loss: 0.4832 - accuracy: 0.8307 - val_loss: 0.5161 - val_accuracy: 0.8186\n",
      "Epoch 5/45\n",
      "860/860 [==============================] - 1s 733us/step - loss: 0.4629 - accuracy: 0.8370 - val_loss: 0.4507 - val_accuracy: 0.8456\n",
      "Epoch 6/45\n",
      "860/860 [==============================] - 1s 716us/step - loss: 0.4448 - accuracy: 0.8417 - val_loss: 0.4706 - val_accuracy: 0.8340\n",
      "Epoch 7/45\n",
      "860/860 [==============================] - 1s 728us/step - loss: 0.4313 - accuracy: 0.8464 - val_loss: 0.4512 - val_accuracy: 0.8400\n",
      "Epoch 8/45\n",
      "860/860 [==============================] - 1s 738us/step - loss: 0.4184 - accuracy: 0.8529 - val_loss: 0.4260 - val_accuracy: 0.8568\n",
      "Epoch 9/45\n",
      "860/860 [==============================] - 1s 722us/step - loss: 0.4083 - accuracy: 0.8540 - val_loss: 0.4442 - val_accuracy: 0.8432\n",
      "Epoch 10/45\n",
      "860/860 [==============================] - 1s 742us/step - loss: 0.3997 - accuracy: 0.8581 - val_loss: 0.4856 - val_accuracy: 0.8338\n",
      "Epoch 11/45\n",
      "860/860 [==============================] - 1s 773us/step - loss: 0.3908 - accuracy: 0.8615 - val_loss: 0.4079 - val_accuracy: 0.8590\n",
      "Epoch 12/45\n",
      "860/860 [==============================] - 1s 766us/step - loss: 0.3800 - accuracy: 0.8649 - val_loss: 0.4072 - val_accuracy: 0.8558\n",
      "Epoch 13/45\n",
      "860/860 [==============================] - 1s 752us/step - loss: 0.3738 - accuracy: 0.8666 - val_loss: 0.4259 - val_accuracy: 0.8490\n",
      "Epoch 14/45\n",
      "860/860 [==============================] - 1s 710us/step - loss: 0.3663 - accuracy: 0.8712 - val_loss: 0.3977 - val_accuracy: 0.8634\n",
      "Epoch 15/45\n",
      "860/860 [==============================] - 1s 731us/step - loss: 0.3596 - accuracy: 0.8711 - val_loss: 0.4144 - val_accuracy: 0.8524\n",
      "Epoch 16/45\n",
      "860/860 [==============================] - 1s 700us/step - loss: 0.3510 - accuracy: 0.8747 - val_loss: 0.3763 - val_accuracy: 0.8680\n",
      "Epoch 17/45\n",
      "860/860 [==============================] - 1s 722us/step - loss: 0.3460 - accuracy: 0.8766 - val_loss: 0.3993 - val_accuracy: 0.8628\n",
      "Epoch 18/45\n",
      "860/860 [==============================] - 1s 721us/step - loss: 0.3406 - accuracy: 0.8771 - val_loss: 0.3843 - val_accuracy: 0.8632\n",
      "Epoch 19/45\n",
      "860/860 [==============================] - 1s 693us/step - loss: 0.3354 - accuracy: 0.8798 - val_loss: 0.4345 - val_accuracy: 0.8458\n",
      "Epoch 20/45\n",
      "860/860 [==============================] - 1s 697us/step - loss: 0.3302 - accuracy: 0.8822 - val_loss: 0.3764 - val_accuracy: 0.8664\n",
      "Epoch 21/45\n",
      "860/860 [==============================] - 1s 726us/step - loss: 0.3240 - accuracy: 0.8849 - val_loss: 0.3865 - val_accuracy: 0.8638\n",
      "Epoch 22/45\n",
      "860/860 [==============================] - 1s 713us/step - loss: 0.3209 - accuracy: 0.8862 - val_loss: 0.3935 - val_accuracy: 0.8582\n",
      "Epoch 23/45\n",
      "860/860 [==============================] - 1s 700us/step - loss: 0.3155 - accuracy: 0.8879 - val_loss: 0.3690 - val_accuracy: 0.8684\n",
      "Epoch 24/45\n",
      "860/860 [==============================] - 1s 703us/step - loss: 0.3115 - accuracy: 0.8885 - val_loss: 0.3659 - val_accuracy: 0.8730\n",
      "Epoch 25/45\n",
      "860/860 [==============================] - 1s 693us/step - loss: 0.3082 - accuracy: 0.8887 - val_loss: 0.3554 - val_accuracy: 0.8720\n",
      "Epoch 26/45\n",
      "860/860 [==============================] - 1s 718us/step - loss: 0.3043 - accuracy: 0.8910 - val_loss: 0.3748 - val_accuracy: 0.8686\n",
      "Epoch 27/45\n",
      "860/860 [==============================] - 1s 758us/step - loss: 0.2997 - accuracy: 0.8917 - val_loss: 0.3611 - val_accuracy: 0.8718\n",
      "Epoch 28/45\n",
      "860/860 [==============================] - 1s 704us/step - loss: 0.2944 - accuracy: 0.8939 - val_loss: 0.3670 - val_accuracy: 0.8730\n",
      "Epoch 29/45\n",
      "860/860 [==============================] - 1s 731us/step - loss: 0.2911 - accuracy: 0.8944 - val_loss: 0.4515 - val_accuracy: 0.8428\n",
      "Epoch 30/45\n",
      "860/860 [==============================] - 1s 748us/step - loss: 0.2883 - accuracy: 0.8961 - val_loss: 0.3549 - val_accuracy: 0.8712\n",
      "Epoch 31/45\n",
      "860/860 [==============================] - 1s 727us/step - loss: 0.2847 - accuracy: 0.8977 - val_loss: 0.3658 - val_accuracy: 0.8724\n",
      "Epoch 32/45\n",
      "860/860 [==============================] - 1s 743us/step - loss: 0.2817 - accuracy: 0.8978 - val_loss: 0.3673 - val_accuracy: 0.8690\n",
      "Epoch 33/45\n",
      "860/860 [==============================] - 1s 749us/step - loss: 0.2785 - accuracy: 0.8993 - val_loss: 0.3571 - val_accuracy: 0.8746\n",
      "Epoch 34/45\n",
      "860/860 [==============================] - 1s 722us/step - loss: 0.2746 - accuracy: 0.8991 - val_loss: 0.3476 - val_accuracy: 0.8758\n",
      "Epoch 35/45\n",
      "860/860 [==============================] - 1s 700us/step - loss: 0.2703 - accuracy: 0.9019 - val_loss: 0.3536 - val_accuracy: 0.8730\n",
      "Epoch 36/45\n",
      "860/860 [==============================] - 1s 722us/step - loss: 0.2675 - accuracy: 0.9014 - val_loss: 0.4234 - val_accuracy: 0.8538\n",
      "Epoch 37/45\n",
      "860/860 [==============================] - 1s 722us/step - loss: 0.2654 - accuracy: 0.9027 - val_loss: 0.3950 - val_accuracy: 0.8682\n",
      "Epoch 38/45\n",
      "860/860 [==============================] - 1s 727us/step - loss: 0.2612 - accuracy: 0.9053 - val_loss: 0.3599 - val_accuracy: 0.8718\n",
      "Epoch 39/45\n",
      "860/860 [==============================] - 1s 715us/step - loss: 0.2597 - accuracy: 0.9063 - val_loss: 0.3482 - val_accuracy: 0.8762\n",
      "Epoch 40/45\n",
      "860/860 [==============================] - 1s 712us/step - loss: 0.2556 - accuracy: 0.9078 - val_loss: 0.3487 - val_accuracy: 0.8764\n",
      "Epoch 41/45\n",
      "860/860 [==============================] - 1s 724us/step - loss: 0.2534 - accuracy: 0.9096 - val_loss: 0.3490 - val_accuracy: 0.8770\n",
      "Epoch 42/45\n",
      "860/860 [==============================] - 1s 721us/step - loss: 0.2502 - accuracy: 0.9089 - val_loss: 0.3481 - val_accuracy: 0.8756\n",
      "Epoch 43/45\n",
      "860/860 [==============================] - 1s 735us/step - loss: 0.2486 - accuracy: 0.9118 - val_loss: 0.3751 - val_accuracy: 0.8718\n",
      "Epoch 44/45\n",
      "860/860 [==============================] - 1s 741us/step - loss: 0.2452 - accuracy: 0.9113 - val_loss: 0.3498 - val_accuracy: 0.8770\n",
      "Epoch 45/45\n",
      "860/860 [==============================] - 1s 744us/step - loss: 0.2419 - accuracy: 0.9139 - val_loss: 0.3450 - val_accuracy: 0.8782\n",
      "860/860 [==============================] - 0s 409us/step\n",
      "[CV] END learning_rate=0.005432590230265345, n_hidden=2, n_units=94; total time=  29.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "1719/1719 [==============================] - 1s 723us/step - loss: 0.7674 - accuracy: 0.7459 - val_loss: 0.5459 - val_accuracy: 0.8154\n",
      "Epoch 2/45\n",
      "1719/1719 [==============================] - 1s 701us/step - loss: 0.5030 - accuracy: 0.8231 - val_loss: 0.4501 - val_accuracy: 0.8478\n",
      "Epoch 3/45\n",
      "1719/1719 [==============================] - 1s 702us/step - loss: 0.4563 - accuracy: 0.8390 - val_loss: 0.5300 - val_accuracy: 0.8018\n",
      "Epoch 4/45\n",
      "1719/1719 [==============================] - 1s 684us/step - loss: 0.4299 - accuracy: 0.8487 - val_loss: 0.4055 - val_accuracy: 0.8588\n",
      "Epoch 5/45\n",
      "1719/1719 [==============================] - 1s 693us/step - loss: 0.4118 - accuracy: 0.8551 - val_loss: 0.3910 - val_accuracy: 0.8640\n",
      "Epoch 6/45\n",
      "1719/1719 [==============================] - 1s 697us/step - loss: 0.3943 - accuracy: 0.8603 - val_loss: 0.3832 - val_accuracy: 0.8698\n",
      "Epoch 7/45\n",
      "1719/1719 [==============================] - 1s 676us/step - loss: 0.3823 - accuracy: 0.8646 - val_loss: 0.3734 - val_accuracy: 0.8688\n",
      "Epoch 8/45\n",
      "1719/1719 [==============================] - 1s 674us/step - loss: 0.3714 - accuracy: 0.8667 - val_loss: 0.3993 - val_accuracy: 0.8548\n",
      "Epoch 9/45\n",
      "1719/1719 [==============================] - 1s 679us/step - loss: 0.3613 - accuracy: 0.8726 - val_loss: 0.3641 - val_accuracy: 0.8708\n",
      "Epoch 10/45\n",
      "1719/1719 [==============================] - 1s 709us/step - loss: 0.3526 - accuracy: 0.8746 - val_loss: 0.3656 - val_accuracy: 0.8674\n",
      "Epoch 11/45\n",
      "1719/1719 [==============================] - 1s 689us/step - loss: 0.3448 - accuracy: 0.8772 - val_loss: 0.3644 - val_accuracy: 0.8698\n",
      "Epoch 12/45\n",
      "1719/1719 [==============================] - 1s 687us/step - loss: 0.3367 - accuracy: 0.8794 - val_loss: 0.3471 - val_accuracy: 0.8750\n",
      "Epoch 13/45\n",
      "1719/1719 [==============================] - 1s 675us/step - loss: 0.3306 - accuracy: 0.8826 - val_loss: 0.3438 - val_accuracy: 0.8774\n",
      "Epoch 14/45\n",
      "1719/1719 [==============================] - 1s 693us/step - loss: 0.3250 - accuracy: 0.8834 - val_loss: 0.3627 - val_accuracy: 0.8662\n",
      "Epoch 15/45\n",
      "1719/1719 [==============================] - 1s 688us/step - loss: 0.3179 - accuracy: 0.8864 - val_loss: 0.3470 - val_accuracy: 0.8700\n",
      "Epoch 16/45\n",
      "1719/1719 [==============================] - 1s 673us/step - loss: 0.3137 - accuracy: 0.8871 - val_loss: 0.3271 - val_accuracy: 0.8808\n",
      "Epoch 17/45\n",
      "1719/1719 [==============================] - 1s 718us/step - loss: 0.3082 - accuracy: 0.8889 - val_loss: 0.3624 - val_accuracy: 0.8670\n",
      "Epoch 18/45\n",
      "1719/1719 [==============================] - 1s 673us/step - loss: 0.3026 - accuracy: 0.8911 - val_loss: 0.3331 - val_accuracy: 0.8798\n",
      "Epoch 19/45\n",
      "1719/1719 [==============================] - 1s 669us/step - loss: 0.2986 - accuracy: 0.8914 - val_loss: 0.3266 - val_accuracy: 0.8812\n",
      "Epoch 20/45\n",
      "1719/1719 [==============================] - 1s 661us/step - loss: 0.2938 - accuracy: 0.8955 - val_loss: 0.3404 - val_accuracy: 0.8764\n",
      "Epoch 21/45\n",
      "1719/1719 [==============================] - 1s 656us/step - loss: 0.2890 - accuracy: 0.8962 - val_loss: 0.3163 - val_accuracy: 0.8856\n",
      "Epoch 22/45\n",
      "1719/1719 [==============================] - 1s 667us/step - loss: 0.2848 - accuracy: 0.8973 - val_loss: 0.3129 - val_accuracy: 0.8854\n",
      "Epoch 23/45\n",
      "1719/1719 [==============================] - 1s 660us/step - loss: 0.2813 - accuracy: 0.8984 - val_loss: 0.3152 - val_accuracy: 0.8862\n",
      "Epoch 24/45\n",
      "1719/1719 [==============================] - 1s 662us/step - loss: 0.2773 - accuracy: 0.8995 - val_loss: 0.3177 - val_accuracy: 0.8804\n",
      "Epoch 25/45\n",
      "1719/1719 [==============================] - 1s 662us/step - loss: 0.2735 - accuracy: 0.9016 - val_loss: 0.3170 - val_accuracy: 0.8824\n",
      "Epoch 26/45\n",
      "1719/1719 [==============================] - 1s 667us/step - loss: 0.2702 - accuracy: 0.9024 - val_loss: 0.3240 - val_accuracy: 0.8834\n",
      "Epoch 27/45\n",
      "1719/1719 [==============================] - 1s 690us/step - loss: 0.2671 - accuracy: 0.9039 - val_loss: 0.3141 - val_accuracy: 0.8860\n",
      "Epoch 28/45\n",
      "1719/1719 [==============================] - 1s 677us/step - loss: 0.2635 - accuracy: 0.9059 - val_loss: 0.3224 - val_accuracy: 0.8802\n",
      "Epoch 29/45\n",
      "1719/1719 [==============================] - 1s 669us/step - loss: 0.2600 - accuracy: 0.9061 - val_loss: 0.3218 - val_accuracy: 0.8828\n",
      "Epoch 30/45\n",
      "1719/1719 [==============================] - 1s 671us/step - loss: 0.2575 - accuracy: 0.9069 - val_loss: 0.3205 - val_accuracy: 0.8834\n",
      "Epoch 31/45\n",
      "1719/1719 [==============================] - 1s 681us/step - loss: 0.2540 - accuracy: 0.9079 - val_loss: 0.3095 - val_accuracy: 0.8874\n",
      "Epoch 32/45\n",
      "1719/1719 [==============================] - 1s 686us/step - loss: 0.2516 - accuracy: 0.9085 - val_loss: 0.3107 - val_accuracy: 0.8876\n",
      "Epoch 33/45\n",
      "1719/1719 [==============================] - 1s 672us/step - loss: 0.2483 - accuracy: 0.9103 - val_loss: 0.3217 - val_accuracy: 0.8870\n",
      "Epoch 34/45\n",
      "1719/1719 [==============================] - 1s 669us/step - loss: 0.2445 - accuracy: 0.9117 - val_loss: 0.3114 - val_accuracy: 0.8874\n",
      "Epoch 35/45\n",
      "1719/1719 [==============================] - 1s 688us/step - loss: 0.2414 - accuracy: 0.9137 - val_loss: 0.3044 - val_accuracy: 0.8916\n",
      "Epoch 36/45\n",
      "1719/1719 [==============================] - 1s 704us/step - loss: 0.2403 - accuracy: 0.9125 - val_loss: 0.3108 - val_accuracy: 0.8910\n",
      "Epoch 37/45\n",
      "1719/1719 [==============================] - 1s 677us/step - loss: 0.2370 - accuracy: 0.9141 - val_loss: 0.3055 - val_accuracy: 0.8910\n",
      "Epoch 38/45\n",
      "1719/1719 [==============================] - 1s 693us/step - loss: 0.2333 - accuracy: 0.9156 - val_loss: 0.3044 - val_accuracy: 0.8908\n",
      "Epoch 39/45\n",
      "1719/1719 [==============================] - 1s 677us/step - loss: 0.2324 - accuracy: 0.9162 - val_loss: 0.3055 - val_accuracy: 0.8908\n",
      "Epoch 40/45\n",
      "1719/1719 [==============================] - 1s 715us/step - loss: 0.2287 - accuracy: 0.9183 - val_loss: 0.3047 - val_accuracy: 0.8894\n",
      "Epoch 41/45\n",
      "1719/1719 [==============================] - 1s 699us/step - loss: 0.2269 - accuracy: 0.9182 - val_loss: 0.3012 - val_accuracy: 0.8940\n",
      "Epoch 42/45\n",
      "1719/1719 [==============================] - 1s 669us/step - loss: 0.2248 - accuracy: 0.9193 - val_loss: 0.3082 - val_accuracy: 0.8908\n",
      "Epoch 43/45\n",
      "1719/1719 [==============================] - 1s 676us/step - loss: 0.2215 - accuracy: 0.9194 - val_loss: 0.3246 - val_accuracy: 0.8824\n",
      "Epoch 44/45\n",
      "1719/1719 [==============================] - 1s 685us/step - loss: 0.2199 - accuracy: 0.9207 - val_loss: 0.3176 - val_accuracy: 0.8902\n",
      "Epoch 45/45\n",
      "1719/1719 [==============================] - 1s 686us/step - loss: 0.2180 - accuracy: 0.9213 - val_loss: 0.3103 - val_accuracy: 0.8882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=KerasClassifier(learning_rate=0.001, loss=&#x27;sparse_categorical_crossentropy&#x27;, model=&lt;function build_model at 0x7ff6e92eb1c0&gt;, n_hidden=1, n_units=1),\n",
       "                   n_iter=2,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.0016834549246003507,\n",
       "                                                          0.02390836445593179,\n",
       "                                                          0.008731907739399207,\n",
       "                                                          0.004725396149933918,\n",
       "                                                          0.0006154014789262349,\n",
       "                                                          0.0006153331256530192,...\n",
       "                                                          0.0011470425674025557,\n",
       "                                                          0.0050214257366256385,\n",
       "                                                          0.0005703073595961107,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.0016212311563941985,\n",
       "                                                          0.0024505367684280496,\n",
       "                                                          0.01115509254171962,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.003203244812844405,\n",
       "                                                          0.004591455636549436,\n",
       "                                                          0.000371554118965828, ...],\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_units&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                    10, 11, 12, 13, 14, 15, 16,\n",
       "                                                    17, 18, 19, 20, 21, 22, 23,\n",
       "                                                    24, 25, 26, 27, 28, 29, 30, ...]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=2,\n",
       "                   estimator=KerasClassifier(learning_rate=0.001, loss=&#x27;sparse_categorical_crossentropy&#x27;, model=&lt;function build_model at 0x7ff6e92eb1c0&gt;, n_hidden=1, n_units=1),\n",
       "                   n_iter=2,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.0016834549246003507,\n",
       "                                                          0.02390836445593179,\n",
       "                                                          0.008731907739399207,\n",
       "                                                          0.004725396149933918,\n",
       "                                                          0.0006154014789262349,\n",
       "                                                          0.0006153331256530192,...\n",
       "                                                          0.0011470425674025557,\n",
       "                                                          0.0050214257366256385,\n",
       "                                                          0.0005703073595961107,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.0016212311563941985,\n",
       "                                                          0.0024505367684280496,\n",
       "                                                          0.01115509254171962,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.003203244812844405,\n",
       "                                                          0.004591455636549436,\n",
       "                                                          0.000371554118965828, ...],\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_units&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                    10, 11, 12, 13, 14, 15, 16,\n",
       "                                                    17, 18, 19, 20, 21, 22, 23,\n",
       "                                                    24, 25, 26, 27, 28, 29, 30, ...]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x7ff6e92eb1c0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_units=1\n",
       "\tn_hidden=1\n",
       "\tlearning_rate=0.001\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=&lt;function build_model at 0x7ff6e92eb1c0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=sparse_categorical_crossentropy\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       "\tn_units=1\n",
       "\tn_hidden=1\n",
       "\tlearning_rate=0.001\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=KerasClassifier(learning_rate=0.001, loss='sparse_categorical_crossentropy', model=<function build_model at 0x7ff6e92eb1c0>, n_hidden=1, n_units=1),\n",
       "                   n_iter=2,\n",
       "                   param_distributions={'learning_rate': [0.0016834549246003507,\n",
       "                                                          0.02390836445593179,\n",
       "                                                          0.008731907739399207,\n",
       "                                                          0.004725396149933918,\n",
       "                                                          0.0006154014789262349,\n",
       "                                                          0.0006153331256530192,...\n",
       "                                                          0.0011470425674025557,\n",
       "                                                          0.0050214257366256385,\n",
       "                                                          0.0005703073595961107,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.0016212311563941985,\n",
       "                                                          0.0024505367684280496,\n",
       "                                                          0.01115509254171962,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.003203244812844405,\n",
       "                                                          0.004591455636549436,\n",
       "                                                          0.000371554118965828, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_units': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                    10, 11, 12, 13, 14, 15, 16,\n",
       "                                                    17, 18, 19, 20, 21, 22, 23,\n",
       "                                                    24, 25, 26, 27, 28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "import sklearn\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_units\": np.arange(1, 100).tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "# wrapper\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_model,\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    n_units=1, n_hidden=1, learning_rate=0.001 # necessary to assign a value here, to make them visible (and tunable) to scikit-learn\n",
    ")\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clf, param_distribs, n_iter=2, cv=2, verbose=2) # toy params\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=45,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_units': 94, 'n_hidden': 2, 'learning_rate': 0.005432590230265345}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 519us/step - loss: 0.3412 - accuracy: 0.8808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3412206470966339, 0.8808000087738037]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
